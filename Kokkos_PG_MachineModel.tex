\chapter{Machine model}\label{C:Model}

After reading this chapter, you will understand the abstract model of
a shared-memory parallel computer which underlies Kokkos.  
Respecting the abstract machine model ensures performance portability.
The model has two components:
\begin{itemize}
\item \emph{Memory spaces}, in which data live
\item \emph{Execution spaces}, which execute parallel operations using
  data in one or more memory spaces
\end{itemize}
All code that uses Kokkos involves relations between memory and execution spaces.
% A given execution space may or may not be able to access data in a
% given memory space.  Users can ask Kokkos if it can.  Users may also
% copy data between any two different memory spaces by using
% \lstinline!deep_copy!.

\section{Motivation}\label{S:Model:Motivation}

Kokkos is a programming model which happens to have a C++ implementation.
As you are first learning Kokkos,
you may find yourself focusing on details of the implementation,
especially if you have less experience with C++ syntax.
However, as the syntax becomes more familiar to you,
you will find it more and more helpful to understand the underlying abstractions.

Kokkos assumes an \emph{abstract machine model},
which represents a shared-memory parallel computer architecture.
The model may represent either a stand-alone computer,
like a laptop or workstation,
or a single ``parallel process'' in a distributed-memory parallel programming model such as MPI (the Message-Passing Interface).
In general, we write \emph{node} to describe the hardware that Kokkos governs.
Kokkos' machine model lets programmers reason about very complicated heterogenous node architectures.
It also lets them start with simple, even sequential architectures,
and gradually port code from there to perform well on more complicated computer architectures.
The abstract machine model might look complicated,
but it reflects computers that companies are actually designing and building.
Many chapters in this Guide show how to use the more complex aspects of the model.
For example, see Chapter \ref {C:Hierarchical},
which shows how to use Kokkos to expose multiple levels of parallelism.

The point of this chapter is that \emph{respecting the abstract machine model ensures performance portability}.
The phrase \emph{performance portability} means that the same code performs reasonably well on many different computer architectures,
with no or minimal\footnote{For example, users might change a single C++ typedef or a single configure-time option.} changes to code.
Kokkos depends on this abstract machine model for performance portability.
\emph{Implementations} of Kokkos may depend on other things for performance portability.
For example, efficiency of \lstinline!parallel_for! in the C++ implementation relies in part on compilers' ability to inline code.
One could imagine a different Kokkos implementation based on source-to-source translation,
that inlines parallel loop bodies into \lstinline!parallel_for! before they reach the compiler.
Kokkos' OpenMP and Pthreads back-ends may rely on the Portable Hardware Locality (hwloc) library
to control assignment of software threads to hardware cores or hyperthreads.
However, Kokkos as an abstract programming model does not depend on these things.

\section{Memory spaces and execution spaces}\label{S:Model:Spaces}

A \emph{memory space} contains data.
Users access those data as k-dimensional typed arrays, where k may be any nonnegative integer.
(Zero-dimensional arrays are single values.  See Chapter \ref{C:View} for details.)
% In the C++ implementation of the Kokkos programming model,
% these memory addresses are pointers,
% which point to contiguous address ranges,
% each of which represents an allocation of data.
The memory space controls dynamic allocation and deallocation of those arrays,
if it allows them at all.

An \emph{execution space} runs Kokkos' parallel operations,
like parallel for, reduce, and scan.  (See Chapter \ref{C:Dispatch}.)
It may access data in some available memory spaces.
Whether an execution space may access data in a memory space
depends on \emph{both} the execution space and the memory space.

\subsection{Types and instances of spaces}\label{SS:Model:Spaces:Types}

Kokkos distinguishes between \emph{types} of spaces, and \emph{instances} of spaces.
For example, a node might have multiple NVIDIA GPUs.
All of these GPUs' memory spaces have the type \lstinline!Kokkos::CudaSpace!,
but each space is a different instance of \lstinline!Kokkos::CudaSpace!.
The common case of using Kokkos presumes a single instance of a given execution or memory space.
In that case, one uses the type of the space as a synonym for the default (single) instance of that space.
When we speak of a space by its type,
we mean the default single instance of that space,
unless we say otherwise.

\subsection{Analogy with operating system processes}\label{SS:Model:Spaces:Analogies}

Here is an analogy: Many operating systems have ``processes.''
A process is like an execution space, in that code may execute in one or more concurrent threads.
Those threads share access to a common stack and heap, which comprise the process' ``memory space.''
Two different processes may not access each other's memory spaces by default.
However, some operating systems have a ``shared memory'' mechanism.\footnote{See e.g., the POSIX \lstinline!shm_open! and related functions.}
This lets different processes share access to a specific region of memory,
which in Kokkos terms is like a ``memory space,'' separate from each process' normal memory space.
Some operating systems also let you open a file,
and then ``memory map'' that file into a contiguous memory address range.\footnote{See e.g., the POSIX \lstinline!mmap! function.}
This makes the file behave like yet another memory space.
Memory-mapped files may have very different performance characteristics than the usual memory,
even though programmers access both ``memory spaces'' through the same interface.
Whether or not a process may access a file depends on both the process and the file.

% Kokkos' abstract machine model may contain $N$ types of execution spaces
% and $M$ types of memory spaces.
% It is possible that $N \neq M$.

\section{Thread teams}\label{S:Model:Teams}

Kokkos supports multiple levels of parallelism.
In particular, it groups threads into \emph{teams}.
A \emph{thread team} is a collection of one or more parallel ``threads'' of execution.
Kokkos allows an arbitrary number of teams -- the \emph{league size}.
Hardware constrains the number of threads in a team -- the \emph{team size}.

Threads in a team can synchronize -- they have a ``barrier'' primitive -- 
and share a ``scratch pad'' memory which they may use for temporary storage.
Scratch pad memory exists only during parallel operations;
allocations in it do not persist across kernels.
Teams themselves may run in any order,
and may not necessarily run all in parallel.
For example, if the user asks for $T$ teams,
the hardware may choose to run them one after another in sequence,
or in groups of up to $G$ teams at a time in parallel.

Users may \emph{nest} parallel operations.
Teams may perform one parallel operation (for, reduce, or scan),
and threads within each team may perform another, possibly different parallel operation.
Different teams may do entirely different things.
For example, all the threads in one team may execute a \lstinline!parallel_for!,
and all the threads in a different team may execute a \lstinline!parallel_scan!.
Different threads within a team may also do different things.
However, performance may vary if threads in a team ``diverge'' in their behavior
(e.g., take different sides of a branch).
Chapter \ref{C:Hierarchical} shows how the C++ implementation of Kokkos exposes thread teams.

NVIDIA's CUDA programming model inspired Kokkos' thread team model.
The scratch pad memory corresponds with CUDA's per-team ``shared memory.''
The ``league / team'' vocabulary comes from OpenMP 4.0,
and has many aspects in common with our thread team model.
We have found that programming to this model results in good performance,
even on computer architectures which only implement parts of the full model.
For example, most multicore processors in common use for high-performance computing lack ``scratch pad'' hardware.
However, if users request a scratch pad size that fits comfortably in the largest cache shared by the threads in a team,
programming as if a scratch pad exists forces users to address locality in their algorithms.
This also reflects the common experience that rewriting a code for more restrictive hardware,
then porting the code \emph{back} to conventional hardware,
tends to improve performance relative to an unoptimized code.

\section{Program execution}\label{S:Model:Exec}

It is tempting to try to define formally what it means for a processor to execute code.
None of us authors have a background in logic or what computer scientists call ``formal methods,''
so our attempt might not go very far!
We will stick with informal definitions and rely on Kokkos' C++ implementation
as an existence proof that the definitions make sense.

Kokkos lets users tell execution spaces to execute parallel operations.
These include parallel for, reduce, and scan (see Chapter \ref{C:Dispatch})
as well as View allocation and initialization (see Chapter \ref{C:View}).
We name the class of all such operations \emph{parallel dispatch}.

From our perspective, there are three kinds of code:
\begin{enumerate}
\item Code executing inside of a Kokkos parallel operation
\item Code outside of a Kokkos parallel operation that asks Kokkos to
  do something (e.g., parallel dispatch itself)
\item Code that has nothing to do with Kokkos
\end{enumerate}
The first category is the most restrictive.
Section \ref{S:Model:Teams} above explains restrictions on inter-team synchronization.
In general, we limit the ability of Kokkos-parallel code to invoke Kokkos operations
(other than for nested parallelism; 
see Section \ref{S:Model:Teams} above and Chapter \ref{C:Hierarchical}).
We also forbid dynamic memory allocation (other than from the team's scratch pad) in parallel operations.
Whether Kokkos-parallel code may invoke operating system routines or third-party libraries
depends on the execution and memory spaces being used.
Regardless, restrictions on inter-team synchronization have implications for things like filesystem access.

\emph{Kokkos threads are for computing in parallel,}
not for overlapping I/O and computation,
and not for making graphical user interfaces responsive.
Use other kinds of threads (e.g., operating system threads) for the latter two purposes.
You may be able to mix Kokkos' parallelism with other kinds of threads;
see Section \ref{SS:Model:Exec:ThreadSafety}.
Kokkos' developers are also working on a task parallelism model
that will work with Kokkos' existing data-parallel constructs.

\subsection{Reproducible reductions and scans}\label{SS:Model:Exec:Repro}

Kokkos promises \emph{nothing} about the order in which the iterations of a parallel loop occur.
However, it \emph{does} promise that if you execute the same parallel reduction or scan,
using the same hardware resources and run-time settings,
then you will get the same results each time you run the operation.
``Same results'' even means ``with respect to floating-point rounding error.''

\subsection{Asynchronous parallel dispatch}\label{SS:Model:Exec:Async}

This concerns the second category of code, that calls Kokkos operations.
In Kokkos, parallel dispatch executes \emph{asynchronously}.  
This means that it may return ``early,'' before it has actually completed.
Nevertheless, it executes \emph{in sequence} with respect to other Kokkos operations on the same execution or memory space.
This matters for things like timing.
For example, a \lstinline!parallel_for! may return ``right away,''
so if you want to measure how long it takes,
you must first call \lstinline!fence()! on that execution space.
This forces all functors to complete before \lstinline!fence()! returns.

\subsection{Thread safety?}\label{SS:Model:Exec:ThreadSafety}

Users may wonder about ``thread safety,'' that is,
whether multiple operating system threads may safely call into Kokkos concurrently.
Kokkos' thread safety depends on both its implementation, 
and on the execution and memory spaces that the implementation uses.
The C++ implementation has made great progress towards (non-Kokkos) thread safety of View memory management.
For now, however, the most portable approach is for only one (non-Kokkos) thread of execution to control Kokkos.
Also, be aware that operating system threads might interfere with Kokkos' performance,
depending on the execution space that you use.

Thread safety with respect to Kokkos' threads is a different matter.
View (see Chapter \ref{C:View}) promises safety of its memory management.
That is, you may safely access Views inside of Kokkos' parallel operations.
Kokkos provides some synchronization constructs as well; see the following section.

\section{Memory consistency}\label{S:Model:Consistency}

A \emph{memory consistency model} describes the behavior of a memory space $M$,
with respect to multiple threads running in an execution space $E$
that access the same data in $M$ concurrently.
One may also encounter this idea as the phrase ``cache coherency.''
We prefer ``memory consistency,'' because Kokkos does not require caches.
Consistency models are a complicated subject which we cannot cover in sufficient detail here.
We encourage readers to refer to standard computer hardware textbooks,
like ``Computer Architecture: A Quantitative Approach'' (Hennessy and Patterson, 2011).

Kokkos imposes a very weak consistency model across an entire execution space.
For example, it does \emph{not} assume sequential consistency.
Much like MPI 3 one-sided communication
or other partitioned global address space (PGAS) programming models,
Kokkos requires an execution space to issue a \emph{memory fence}
to a given memory space, 
in order to bring that memory space into a consistent state.
The fence forces completion of all outstanding memory writes,
and reorders all loads to occur after all those writes complete.

\subsection{Atomic updates}\label{SS:Model:Consistency:Atomic}

Some execution spaces may implement \emph{atomic updates} with respect to some memory spaces.
An atomic update runs on an execution space, and changes a word of data in a memory space.
The atomic update behaves atomically with respect to other atomic updates happening concurrently by that execution space on that memory space.
``Behaves atomically'' means that all of the atomic updates will complete,
and the word of data will be changed in a way that respects some order of those update operations.
Kokkos does not promise any particular order.
Furthermore, for a nonatomic memory read or write to ``see'' the results of atomic updates,
the execution space must first execute a \lstinline!fence()! operation to that memory space.
