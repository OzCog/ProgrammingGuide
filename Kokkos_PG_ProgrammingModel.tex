
\section{Programming Model}

The programming model Kokkos is characterized by 6 core abstractions: Execution Spaces, Execution Patterns, Execution Policies, Memory Spaces, Memory Layout and Memory Traits. 
These abstraction concepts allow the formulation of generic algorithms and data structures which can then be mapped to different types of architectures. 
Effectively they allow for compile time transformation of algorithms to allow for adaptions of varying degrees of hardware parallelism as well as of the memory hierarchy. 

\subsection{Execution Spaces}

An Execution Space is the place {\it Where} code can actually be executed. 
For example on current Hybrid GPU / CPU systems there are two types of execution spaces: the GPU cores and the CPU cores. 
In the future this could include Processing in Memory (PIM) modules or different core types on a heterogenous CPU.
In principle this can also be used to introduce remote memory spaces, e.g. the capability of sending work to a different node.
Execution Spaces thus give an application developer the means to target different parts of a heterogenous hardware architecture.

\subsection{Execution Patterns}

Execution Patterns are the fundamental parallel algorithms in which an application has to be expressed.
Examples are \lstinline|parallel_for|: execute a function in undeterminded order a specified amount of times.,
\lstinline|parallel_reduce|: which combines a \lstinline|parallel_for| execution with a reduction operation,
\lstinline|parallel_scan|: which combines a \lstinline|parallel_for| operation with a prefix or postfix scan on output values of each operation, and
\lstinline|task|: which executes a single function with dependencies on other functions.
Expressing an application in these patterns allows the underlying implementation or the used compiler to reason about valid transformations.
For example all \lstinline|parallel_***| patterns allow unspecified execution order, and only promise deterministic results of the reductions themselves.
This enables different mapping patterns on different hardware such as assignment of iterations to threads or vector lanes. 

\subsection{Execution Policies}

An Execution Policy determines together with an Execution Pattern {\it How} a function is executed.

\subsection{Memory Spaces}

Memory Spaces are the places {\it Where} data resides.
They specify physical location of data as well as certain access characteristics. 
Different physical locations correspond to things such as high bandwidth memory, on die scratch memory or non-volatile bulk storage.
Different logical memory spaces allow for concepts such as UVM memory in the CUDA programming model, which is accessible from Host and GPU. 
Memory Spaces also can be used to express remote memory locations.
Furthermore they encapsulate functionality such as consistency control and persistence scopes.

\subsection{Memory Layout}

Layouts express the mapping from logical (or algorithmical) indicies to address offset for a data allocation. 
By adopting appropriate layouts for memort structures an application can optimise data access patterns in a given algorithm.
If an implementation provides polymorphic layouts (i.e. a data structure can be instantiated at compile or runtime with different layouts) an architecture dependent optimisation can be performed.

\subsection{Memory Traits}

Memory Traits specify how a data structure is accessed in an algorithm. 
Traits express usage scenarios such as atomic access, random access and streaming loads or stores.
By putting such attributes on data structures, an implementation of the programming model can insert optimal load and store operations.
If a compiler implements the programming model, it could reason about the access modes and use that to inform code transformations.   

